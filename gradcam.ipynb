{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd9b5ba2-55c6-48b7-b89c-bd7555864156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/756 [00:00<?, ?it/s]\n",
      " 25%|██▍       | 134/546 [00:00<00:00, 8817.65it/s]\n",
      "  0%|          | 0/672 [00:00<?, ?it/s]\n",
      "  5%|▍         | 28/588 [00:00<00:00, 22133.53it/s]\n",
      "  0%|          | 0/630 [00:00<?, ?it/s]\n",
      " 11%|█         | 62/588 [00:00<00:00, 20346.36it/s]\n",
      "  0%|          | 0/840 [00:00<?, ?it/s]\n",
      " 24%|██▍       | 133/546 [00:00<00:00, 20736.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# 原340行\n",
    "import torch, cv2, os\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from tqdm import trange\n",
    "from PIL import Image\n",
    "from nets.yolo import YoloBody\n",
    "from pytorch_grad_cam import GradCAMPlusPlus,GradCAM,XGradCAM,EigenCAM,RandomCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "def letterbox(im,new_shape=(640,640),color=(114,114,114),stride=32):\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]\n",
    "    dw, dh = np.mod(dw, stride)/2, np.mod(dh, stride)/2  # minimum rectangle\n",
    "    im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    return cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color), im# add border\n",
    "\n",
    "class ActivationsAndGradients:#从目标中间层提取激活值并注册梯度\n",
    "    def __init__(self, model, target_layers, reshape_transform):\n",
    "        self.model = model\n",
    "        self.gradients,self.activations,self.handles = [],[],[]\n",
    "        for target_layer in target_layers:#为每一层注册前向hook来保存激活值和梯度\n",
    "            self.handles.append(target_layer.register_forward_hook(self.save_activation)); self.handles.append(target_layer.register_forward_hook(self.save_gradient))\n",
    "    def save_activation(self, module, input, output):#模型出入这些好像是自动捕捉的\n",
    "        self.activations.append(output.cpu().detach())\n",
    "    def save_gradient(self, module, input, output):\n",
    "        def _store_grad(grad):#only register hooks on tensor requires grad.\n",
    "            self.gradients = [grad.cpu().detach()] + self.gradients\n",
    "        output.register_hook(_store_grad)\n",
    "    def 后处理(self, boxes_,logits_):#此后处理非nms！\n",
    "        sorted, indices = torch.sort(logits_.max(1)[0], descending=True)\n",
    "        return torch.transpose(logits_[0], dim0=0, dim1=1)[indices[0]], torch.transpose(boxes_[0], dim0=0, dim1=1)[indices[0]]\n",
    "    def __call__(self, x):\n",
    "        self.gradients,self.activations = [],[]\n",
    "        return [self.后处理(self.model(x)[0],self.model(x)[1])]\n",
    "    def release(self):\n",
    "        for handle in self.handles:handle.remove()\n",
    "\n",
    "class yolov8_target(torch.nn.Module):\n",
    "    def __init__(self, ouput_type, conf, ratio) -> None:\n",
    "        super().__init__()\n",
    "        self.ouput_type = ouput_type\n",
    "        self.conf = conf\n",
    "        self.ratio = ratio\n",
    "    def forward(self, data):\n",
    "        post_result, pre_post_boxes, result = data[0],data[1],[]\n",
    "        for i in trange(int(post_result.size(0) * self.ratio)):\n",
    "            if float(post_result[i].max()) < self.conf: break\n",
    "            if self.ouput_type == 'class' or self.ouput_type == 'all':\n",
    "                result.append(post_result[i].max())\n",
    "            elif self.ouput_type == 'box' or self.ouput_type == 'all':\n",
    "                for j in range(4):result.append(pre_post_boxes[i, j])\n",
    "        return sum(result)#浓缩为一个整体\n",
    "\n",
    "class yolov8_heatmap:\n",
    "    def __init__(self,weight,device,method,layer,backward_type,信阈,ratio):\n",
    "        model = YoloBody([640, 640], 7, 'n', pretrained=False)\n",
    "        pretrained_dict = torch.load(weight, map_location='cpu')\n",
    "        model.load_state_dict(pretrained_dict)\n",
    "        for p in model.parameters(): p.requires_grad_(True)#梯降才能返梯度\n",
    "        model.eval();# print(model)\n",
    "        target = yolov8_target(backward_type, 信阈, ratio)\n",
    "        target_layers = [model.backbone.dark3.头]#此处为网络具体层的输出，用\".\"嵌套，若为序列则可用[0~序列长度]如[1]代替\".头\"\n",
    "        method = eval(method)(model, target_layers)\n",
    "        method.activations_and_grads = ActivationsAndGradients(model, target_layers, None)\n",
    "        self.__dict__.update(locals())\n",
    "    def process(self, img_path, save_path):\n",
    "        if not img_path.endswith('.jpg'):return#可能是\"images/.ipynb_checkpoints\"\n",
    "        img = letterbox(cv2.imread(img_path))[0]\n",
    "        img = np.float32(cv2.cvtColor(img,cv2.COLOR_BGR2RGB)) / 255.0\n",
    "        try:grayscale_cam = self.method(torch.from_numpy(np.transpose(img,axes=[2,0,1])).unsqueeze(0).to(self.device), [self.target])\n",
    "        except AttributeError as e:return\n",
    "        cam_image = show_cam_on_image(img, grayscale_cam[0, :], use_rgb=True)\n",
    "        Image.fromarray(cam_image).save(save_path)\n",
    "    def __call__(self, img_path, save_path):\n",
    "        os.makedirs(save_path, exist_ok=True)#建立新的保存地址\n",
    "        if os.path.isdir(img_path):#是目录则在保存路径下存为各名，否则一张结果图\n",
    "            for img_path_ in os.listdir(img_path):\n",
    "                self.process(f'{img_path}/{img_path_}',f'{save_path}/{img_path_}')\n",
    "        else:self.process(img_path, f'{save_path}/result.png')\n",
    "        \n",
    "def get_params():\n",
    "    params={'weight': '出简701.pth',\n",
    "        'device': 'cpu',\n",
    "        'method': 'GradCAM',# GradCAMPlusPlus,GradCAM,XGradCAM,EigenCAM,RandomCAM\n",
    "        'layer': '[0, 1]',#[10, 12, 14, 16, 18],\n",
    "        'backward_type': 'box', # class, box, all\n",
    "        '信阈': 0.00001,'ratio': 0.1} # 0.2//0.02-0.1 ，取样占比\n",
    "    return params\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = yolov8_heatmap(**get_params())\n",
    "    model('images', 'result')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
